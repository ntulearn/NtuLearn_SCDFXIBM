{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>emergency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword location                                               text  \\\n",
       "0     NaN      NaN                 Just happened a terrible car crash   \n",
       "1     NaN      NaN  Heard about #earthquake is different cities, s...   \n",
       "2     NaN      NaN  there is a forest fire at spot pond, geese are...   \n",
       "3     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n",
       "4     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "   emergency  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('twitter_test.csv')\n",
    "data[\"emergency\"] = np.nan\n",
    "data.drop(columns=['id'],inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions for cleaning tasks\n",
    "\n",
    "def remove_punct(text):\n",
    "    no_punct = ''.join(char for char in text if char not in string.punctuation)\n",
    "    return no_punct\n",
    "\n",
    "# creates a list of words\n",
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    return tokens\n",
    "\n",
    "# remove common words with no meaning e.g. connectors\n",
    "def remove_stopwords(token_list):\n",
    "    text = [word for word in token_list if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "# convert words into their root forms\n",
    "def lemmatize(text):\n",
    "    lemmatized_text = [wn.lemmatize(word) for word in text]\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>emergency</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>[just, happened, a, terrible, car, crash]</td>\n",
       "      <td>[happened, terrible, car, crash]</td>\n",
       "      <td>[happened, terrible, car, crash]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about earthquake is different cities sta...</td>\n",
       "      <td>[heard, about, earthquake, is, different, citi...</td>\n",
       "      <td>[heard, earthquake, different, cities, stay, s...</td>\n",
       "      <td>[heard, earthquake, different, city, stay, saf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond geese are ...</td>\n",
       "      <td>[there, is, a, forest, fire, at, spot, pond, g...</td>\n",
       "      <td>[forest, fire, spot, pond, geese, fleeing, acr...</td>\n",
       "      <td>[forest, fire, spot, pond, goose, fleeing, acr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting Spokane wildfires</td>\n",
       "      <td>[apocalypse, lighting, spokane, wildfires]</td>\n",
       "      <td>[apocalypse, lighting, spokane, wildfires]</td>\n",
       "      <td>[apocalypse, lighting, spokane, wildfire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>[typhoon, soudelor, kills, 28, in, china, and,...</td>\n",
       "      <td>[typhoon, soudelor, kills, 28, china, taiwan]</td>\n",
       "      <td>[typhoon, soudelor, kill, 28, china, taiwan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword location                                               text  \\\n",
       "0     NaN      NaN                 Just happened a terrible car crash   \n",
       "1     NaN      NaN  Heard about #earthquake is different cities, s...   \n",
       "2     NaN      NaN  there is a forest fire at spot pond, geese are...   \n",
       "3     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n",
       "4     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "   emergency                                         clean_text  \\\n",
       "0        NaN                 Just happened a terrible car crash   \n",
       "1        NaN  Heard about earthquake is different cities sta...   \n",
       "2        NaN  there is a forest fire at spot pond geese are ...   \n",
       "3        NaN              Apocalypse lighting Spokane wildfires   \n",
       "4        NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0          [just, happened, a, terrible, car, crash]   \n",
       "1  [heard, about, earthquake, is, different, citi...   \n",
       "2  [there, is, a, forest, fire, at, spot, pond, g...   \n",
       "3         [apocalypse, lighting, spokane, wildfires]   \n",
       "4  [typhoon, soudelor, kills, 28, in, china, and,...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0                   [happened, terrible, car, crash]   \n",
       "1  [heard, earthquake, different, cities, stay, s...   \n",
       "2  [forest, fire, spot, pond, geese, fleeing, acr...   \n",
       "3         [apocalypse, lighting, spokane, wildfires]   \n",
       "4      [typhoon, soudelor, kills, 28, china, taiwan]   \n",
       "\n",
       "                                          lemmatized  \n",
       "0                   [happened, terrible, car, crash]  \n",
       "1  [heard, earthquake, different, city, stay, saf...  \n",
       "2  [forest, fire, spot, pond, goose, fleeing, acr...  \n",
       "3          [apocalypse, lighting, spokane, wildfire]  \n",
       "4       [typhoon, soudelor, kill, 28, china, taiwan]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_text'] = data['text'].apply(lambda x: remove_punct(x))\n",
    "data['tokenized'] = data['clean_text'].apply(lambda x: tokenize(x.lower()))\n",
    "data['no_stopwords'] = data['tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "data['lemmatized'] = data['no_stopwords'].apply(lambda x: lemmatize(x))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>emergency</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>body_len</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>['our', 'deeds', 'are', 'the', 'reason', 'of',...</td>\n",
       "      <td>['deeds', 'reason', 'earthquake', 'may', 'alla...</td>\n",
       "      <td>['deed', 'reason', 'earthquake', 'may', 'allah...</td>\n",
       "      <td>57</td>\n",
       "      <td>0.2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask Canada</td>\n",
       "      <td>['forest', 'fire', 'near', 'la', 'ronge', 'sas...</td>\n",
       "      <td>['forest', 'fire', 'near', 'la', 'ronge', 'sas...</td>\n",
       "      <td>['forest', 'fire', 'near', 'la', 'ronge', 'sas...</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>All residents asked to shelter in place are be...</td>\n",
       "      <td>['all', 'residents', 'asked', 'to', 'shelter',...</td>\n",
       "      <td>['residents', 'asked', 'shelter', 'place', 'no...</td>\n",
       "      <td>['resident', 'asked', 'shelter', 'place', 'not...</td>\n",
       "      <td>112</td>\n",
       "      <td>-0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>['13000', 'people', 'receive', 'wildfires', 'e...</td>\n",
       "      <td>['13000', 'people', 'receive', 'wildfires', 'e...</td>\n",
       "      <td>['13000', 'people', 'receive', 'wildfire', 'ev...</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>['just', 'got', 'sent', 'this', 'photo', 'from...</td>\n",
       "      <td>['got', 'sent', 'photo', 'ruby', 'alaska', 'sm...</td>\n",
       "      <td>['got', 'sent', 'photo', 'ruby', 'alaska', 'sm...</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 keyword location  \\\n",
       "0           0     NaN      NaN   \n",
       "1           1     NaN      NaN   \n",
       "2           2     NaN      NaN   \n",
       "3           3     NaN      NaN   \n",
       "4           4     NaN      NaN   \n",
       "\n",
       "                                                text  emergency  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...          1   \n",
       "1             Forest fire near La Ronge Sask. Canada          1   \n",
       "2  All residents asked to 'shelter in place' are ...          1   \n",
       "3  13,000 people receive #wildfires evacuation or...          1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...          1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  Our Deeds are the Reason of this earthquake Ma...   \n",
       "1              Forest fire near La Ronge Sask Canada   \n",
       "2  All residents asked to shelter in place are be...   \n",
       "3  13000 people receive wildfires evacuation orde...   \n",
       "4  Just got sent this photo from Ruby Alaska as s...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  ['our', 'deeds', 'are', 'the', 'reason', 'of',...   \n",
       "1  ['forest', 'fire', 'near', 'la', 'ronge', 'sas...   \n",
       "2  ['all', 'residents', 'asked', 'to', 'shelter',...   \n",
       "3  ['13000', 'people', 'receive', 'wildfires', 'e...   \n",
       "4  ['just', 'got', 'sent', 'this', 'photo', 'from...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  ['deeds', 'reason', 'earthquake', 'may', 'alla...   \n",
       "1  ['forest', 'fire', 'near', 'la', 'ronge', 'sas...   \n",
       "2  ['residents', 'asked', 'shelter', 'place', 'no...   \n",
       "3  ['13000', 'people', 'receive', 'wildfires', 'e...   \n",
       "4  ['got', 'sent', 'photo', 'ruby', 'alaska', 'sm...   \n",
       "\n",
       "                                          lemmatized  body_len  sentiment  \n",
       "0  ['deed', 'reason', 'earthquake', 'may', 'allah...        57     0.2732  \n",
       "1  ['forest', 'fire', 'near', 'la', 'ronge', 'sas...        32    -0.3400  \n",
       "2  ['resident', 'asked', 'shelter', 'place', 'not...       112    -0.2960  \n",
       "3  ['13000', 'people', 'receive', 'wildfire', 'ev...        57     0.0000  \n",
       "4  ['got', 'sent', 'photo', 'ruby', 'alaska', 'sm...        72     0.0000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('clean.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tf-idf\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit(train_data['lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = X_tfidf.transform(data['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('RF_Model.pkl', 'rb') as file:  \n",
    "    model = pickle.load(file)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_tfidf_feat)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emergency'] = y_pred\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('emergency_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
